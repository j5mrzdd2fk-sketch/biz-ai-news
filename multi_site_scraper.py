#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒãƒ«ãƒã‚µã‚¤ãƒˆå¯¾å¿œ AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & è¦ç´„ãƒ„ãƒ¼ãƒ«

å¯¾å¿œã‚µã‚¤ãƒˆ:
- Ledge.ai
- AINOW
- PR TIMES
- ZDNet Japan
- ITmedia AI+
"""

import os
import time
import traceback
from datetime import datetime
from typing import Optional
from dotenv import load_dotenv
from openai import OpenAI

# Google Sheetsé–¢é€£
import gspread
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
from scrapers import LedgeAiScraper, AINowScraper, PRTimesScraper, ZDNetScraper, ITmediaAiPlusScraper

# ãƒ­ã‚°è¨­å®š
from logger_config import get_scraper_logger, log_exception

# ãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–
logger = get_scraper_logger()

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# Google Sheets APIã®ã‚¹ã‚³ãƒ¼ãƒ—
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive.file'
]

# èªè¨¼æƒ…å ±ã®ãƒ‘ã‚¹
CREDENTIALS_FILE = "/Users/masak/Desktop/ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°/credentials.json"
TOKEN_FILE = "/Users/masak/Desktop/ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°/token.json"

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå
SPREADSHEET_NAME = "AIãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ï¼ˆãƒãƒ«ãƒã‚µã‚¤ãƒˆï¼‰"

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰
KEYWORD_CATEGORIES = {
    "ä¼æ¥­åŠ¹ç‡åŒ–": [
        "æ¥­å‹™åŠ¹ç‡åŒ–", "æ¥­å‹™æ”¹å–„", "ç”Ÿç”£æ€§å‘ä¸Š", "ã‚³ã‚¹ãƒˆå‰Šæ¸›", "åƒãæ–¹æ”¹é©",
        "è‡ªå‹•åŒ–", "åŠ¹ç‡åŒ–", "çœåŠ›åŒ–", "æ™‚çŸ­",
    ],
    "DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–": [
        "DX", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–", "ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©",
    ],
    "ä¼æ¥­å°å…¥": [
        "ä¼æ¥­å°å…¥", "ä¼æ¥­äº‹ä¾‹", "å›½å†…ä¼æ¥­", "å°å…¥äº‹ä¾‹", "æ´»ç”¨äº‹ä¾‹", "ãƒ“ã‚¸ãƒã‚¹æ´»ç”¨",
    ],
    "AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": [
        "AI", "äººå·¥çŸ¥èƒ½", "æ©Ÿæ¢°å­¦ç¿’", "ç”ŸæˆAI", "ChatGPT", "GPT", "LLM",
        "ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹", "è‡ªå‹•åŒ–", "AIå°å…¥", "AIæ´»ç”¨",
        "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "æŠ€è¡“", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ‡ã‚¸ã‚¿ãƒ«", "ã‚¯ãƒ©ã‚¦ãƒ‰",
        "API", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢", "ã‚·ã‚¹ãƒ†ãƒ ", "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ",
    ],
}

# å…¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ï¼‰
KEYWORDS = [
    keyword for keywords in KEYWORD_CATEGORIES.values() for keyword in keywords
]


class ArticleSummarizer:
    """OpenAI APIã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’è¦ç´„ãƒ»è©•ä¾¡ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def summarize_and_score(self, article: dict) -> dict:
        """è¨˜äº‹ã‚’è¦ç´„ã—ã€é‡è¦åº¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹"""
        content = article.get("content", "")
        title = article.get("title", "")
        
        if not content:
            return {"summary": "è¨˜äº‹æœ¬æ–‡ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", "score": 1}
        
        prompt = f"""ä»¥ä¸‹ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘
{title}

ã€æœ¬æ–‡ã€‘
{content[:3000]}

---
ä»¥ä¸‹ã®2ã¤ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

## 1. è¦ç´„ï¼ˆ150ã€œ200æ–‡å­—ï¼‰
- ä½•ãŒç™ºè¡¨/ç™ºç”Ÿã—ãŸã®ã‹ï¼ˆWho/Whatï¼‰
- ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ã‚„æ„ç¾©
- ä»Šå¾Œã®å±•æœ›ï¼ˆã‚ã‚Œã°ï¼‰

## 2. é‡è¦åº¦ã‚¹ã‚³ã‚¢ï¼ˆ1ã€œ5ã®æ•´æ•°ï¼‰
ä»¥ä¸‹ã®åŸºæº–ã§è©•ä¾¡ï¼š
- 5: æ¥­ç•Œå…¨ä½“ã«å½±éŸ¿ã™ã‚‹é‡å¤§ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆå¤§æ‰‹ä¼æ¥­ã®å¤§è¦æ¨¡å°å…¥ã€ç”»æœŸçš„ãªæŠ€è¡“ç™ºè¡¨ãªã©ï¼‰
- 4: æ³¨ç›®ã™ã¹ãé‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆå…·ä½“çš„ãªæˆæœãƒ»æ•°å€¤ã‚ã‚Šã€å›½å†…å¤§æ‰‹ä¼æ¥­ã®äº‹ä¾‹ï¼‰
- 3: å‚è€ƒã«ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆä¸€èˆ¬çš„ãªå°å…¥äº‹ä¾‹ã€æŠ€è¡“è§£èª¬ï¼‰
- 2: è»½ã„æƒ…å ±ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå‘ŠçŸ¥ã€å°è¦æ¨¡ãªå–ã‚Šçµ„ã¿ï¼‰
- 1: é‡è¦åº¦ä½ã„ï¼ˆãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®ã¿ã€å†…å®¹è–„ã„ï¼‰

---
ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
ã€è¦ç´„ã€‘
ï¼ˆè¦ç´„æ–‡ï¼‰

ã€ã‚¹ã‚³ã‚¢ã€‘
ï¼ˆ1ã€œ5ã®æ•°å­—ã®ã¿ï¼‰"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼åˆ†é‡ã«ç²¾é€šã—ãŸãƒ“ã‚¸ãƒã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’çš„ç¢ºã«è¦ç´„ã—ã€ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ã«ã¨ã£ã¦ã®é‡è¦åº¦ã‚’è©•ä¾¡ã—ã¾ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=600,
                temperature=0.3
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # è¦ç´„ã¨ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
            summary = ""
            score = 3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
            if "ã€è¦ç´„ã€‘" in result_text:
                parts = result_text.split("ã€ã‚¹ã‚³ã‚¢ã€‘")
                summary_part = parts[0].replace("ã€è¦ç´„ã€‘", "").strip()
                summary = summary_part
                
                if len(parts) > 1:
                    score_text = parts[1].strip()
                    # æ•°å­—ã‚’æŠ½å‡º
                    for char in score_text:
                        if char.isdigit():
                            score = int(char)
                            break
            else:
                summary = result_text
            
            # ã‚¹ã‚³ã‚¢ã‚’1-5ã®ç¯„å›²ã«åˆ¶é™
            score = max(1, min(5, score))
            
            return {"summary": summary, "score": score}
            
        except Exception as e:
            log_exception(logger, e, f"OpenAI APIè¦ç´„ã‚¨ãƒ©ãƒ¼ (ã‚¿ã‚¤ãƒˆãƒ«: {title[:50]})")
            return {"summary": f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}", "score": 1}


class GoogleSheetsExporter:
    """çµæœã‚’Google Sheetsã«å‡ºåŠ›ã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚·ãƒ¼ãƒˆå¯¾å¿œï¼‰"""
    
    def __init__(self):
        self.creds = None
        self.client = None
        self.spreadsheet = None
        self.worksheets = {}  # ã‚«ãƒ†ã‚´ãƒªå -> worksheet
        self.existing_urls = set()
        self.existing_titles = set()
        
        self._authenticate()
        self._setup_spreadsheet()
    
    def _authenticate(self):
        """Googleèªè¨¼ã‚’è¡Œã†"""
        print("ğŸ” Googleèªè¨¼ä¸­...")
        logger.info("Googleèªè¨¼ã‚’é–‹å§‹")
        
        try:
            if os.path.exists(TOKEN_FILE):
                self.creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)
            
            if not self.creds or not self.creds.valid:
                if self.creds and self.creds.expired and self.creds.refresh_token:
                    logger.info("ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ä¸­")
                    self.creds.refresh(Request())
                else:
                    logger.info("æ–°ã—ã„èªè¨¼ãƒ•ãƒ­ãƒ¼ã‚’é–‹å§‹")
                    flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
                    self.creds = flow.run_local_server(port=0)
                
                with open(TOKEN_FILE, 'w') as token:
                    token.write(self.creds.to_json())
                logger.info("ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
            self.client = gspread.authorize(self.creds)
            print("âœ… Googleèªè¨¼å®Œäº†")
            logger.info("Googleèªè¨¼å®Œäº†")
        except FileNotFoundError as e:
            error_msg = f"èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {CREDENTIALS_FILE}"
            log_exception(logger, e, "Googleèªè¨¼ã‚¨ãƒ©ãƒ¼")
            raise FileNotFoundError(error_msg) from e
        except Exception as e:
            log_exception(logger, e, "Googleèªè¨¼ã‚¨ãƒ©ãƒ¼")
            raise
    
    def _setup_spreadsheet(self):
        """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚·ãƒ¼ãƒˆï¼‰"""
        is_new = False
        try:
            self.spreadsheet = self.client.open(SPREADSHEET_NAME)
            print(f"ğŸ“‚ æ—¢å­˜ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ãã¾ã—ãŸ: {SPREADSHEET_NAME}")
            logger.info(f"æ—¢å­˜ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ãã¾ã—ãŸ: {SPREADSHEET_NAME}")
        except gspread.SpreadsheetNotFound:
            print(f"ğŸ“„ æ–°è¦ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ: {SPREADSHEET_NAME}")
            logger.info(f"æ–°è¦ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ: {SPREADSHEET_NAME}")
            try:
                self.spreadsheet = self.client.create(SPREADSHEET_NAME)
                is_new = True
                print(f"ğŸ”— ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL: {self.spreadsheet.url}")
                logger.info(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL: {self.spreadsheet.url}")
            except Exception as e:
                log_exception(logger, e, "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼")
                raise
        except Exception as e:
            log_exception(logger, e, "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ©ãƒ¼")
            raise
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚·ãƒ¼ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        category_names = list(KEYWORD_CATEGORIES.keys()) + ["ãã®ä»–"]
        
        for category in category_names:
            try:
                ws = self.spreadsheet.worksheet(category)
                self.worksheets[category] = ws
                logger.debug(f"ã‚·ãƒ¼ãƒˆã€Œ{category}ã€ã‚’èª­ã¿è¾¼ã¿")
            except gspread.WorksheetNotFound:
                try:
                    ws = self.spreadsheet.add_worksheet(title=category, rows=200, cols=10)
                    self.worksheets[category] = ws
                    self._setup_sheet_headers(ws, category)
                    logger.info(f"æ–°è¦ã‚·ãƒ¼ãƒˆã€Œ{category}ã€ã‚’ä½œæˆã—ã¾ã—ãŸ")
                except Exception as e:
                    log_exception(logger, e, f"ã‚·ãƒ¼ãƒˆã€Œ{category}ã€ä½œæˆã‚¨ãƒ©ãƒ¼")
                    raise
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ãƒ¼ãƒˆ1ã‚’å‰Šé™¤ï¼ˆæ–°è¦ã®å ´åˆï¼‰
        if is_new:
            try:
                default_sheet = self.spreadsheet.worksheet("ã‚·ãƒ¼ãƒˆ1")
                self.spreadsheet.del_worksheet(default_sheet)
                logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒ¼ãƒˆã€Œã‚·ãƒ¼ãƒˆ1ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒ¼ãƒˆå‰Šé™¤ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
        
        # æ—¢å­˜URLã‚’èª­ã¿è¾¼ã¿
        self._load_existing_urls()
    
    def _setup_sheet_headers(self, worksheet, category: str):
        """ã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¨æ›¸å¼ã‚’è¨­å®š"""
        headers = ["No.", "ã‚½ãƒ¼ã‚¹", "ã‚¿ã‚¤ãƒˆãƒ«", "æ—¥ä»˜", "ã‚¿ã‚°", "é‡è¦åº¦", "è¦ç´„", "URL", "å®ŸURL", "ã‚«ãƒ†ã‚´ãƒª"]
        worksheet.update(values=[headers], range_name='A1:J1')
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è‰²è¨­å®š
        colors = {
            "ä¼æ¥­åŠ¹ç‡åŒ–": {'red': 0.15, 'green': 0.35, 'blue': 0.55},
            "DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–": {'red': 0.25, 'green': 0.45, 'blue': 0.30},
            "ä¼æ¥­å°å…¥": {'red': 0.50, 'green': 0.30, 'blue': 0.45},
            "AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": {'red': 0.30, 'green': 0.20, 'blue': 0.60},
            "ãã®ä»–": {'red': 0.40, 'green': 0.40, 'blue': 0.40},
        }
        bg_color = colors.get(category, {'red': 0.3, 'green': 0.3, 'blue': 0.5})
        
        sheet_id = worksheet.id
        requests = [
            # ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸å¼
            {'repeatCell': {
                'range': {'sheetId': sheet_id, 'startRowIndex': 0, 'endRowIndex': 1, 'startColumnIndex': 0, 'endColumnIndex': 8},
                'cell': {'userEnteredFormat': {
                    'backgroundColor': bg_color,
                    'textFormat': {'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}, 'bold': True, 'fontSize': 11},
                    'horizontalAlignment': 'CENTER', 'verticalAlignment': 'MIDDLE'
                }},
                'fields': 'userEnteredFormat(backgroundColor,textFormat,horizontalAlignment,verticalAlignment)'
            }},
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œé«˜ã•
            {'updateDimensionProperties': {
                'range': {'sheetId': sheet_id, 'dimension': 'ROWS', 'startIndex': 0, 'endIndex': 1},
                'properties': {'pixelSize': 40}, 'fields': 'pixelSize'}},
            # åˆ—å¹…
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 0, 'endIndex': 1}, 'properties': {'pixelSize': 45}, 'fields': 'pixelSize'}},   # No.
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 1, 'endIndex': 2}, 'properties': {'pixelSize': 100}, 'fields': 'pixelSize'}},  # ã‚½ãƒ¼ã‚¹
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 2, 'endIndex': 3}, 'properties': {'pixelSize': 300}, 'fields': 'pixelSize'}},  # ã‚¿ã‚¤ãƒˆãƒ«
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 3, 'endIndex': 4}, 'properties': {'pixelSize': 100}, 'fields': 'pixelSize'}},  # æ—¥ä»˜
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 4, 'endIndex': 5}, 'properties': {'pixelSize': 140}, 'fields': 'pixelSize'}},  # ã‚¿ã‚°
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 5, 'endIndex': 6}, 'properties': {'pixelSize': 70}, 'fields': 'pixelSize'}},   # é‡è¦åº¦
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 6, 'endIndex': 7}, 'properties': {'pixelSize': 500}, 'fields': 'pixelSize'}},  # è¦ç´„
            {'updateDimensionProperties': {'range': {'sheetId': sheet_id, 'dimension': 'COLUMNS', 'startIndex': 7, 'endIndex': 8}, 'properties': {'pixelSize': 100}, 'fields': 'pixelSize'}},  # URL
            # ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®š
            {'updateSheetProperties': {
                'properties': {'sheetId': sheet_id, 'gridProperties': {'frozenRowCount': 1}},
                'fields': 'gridProperties.frozenRowCount'
            }}
        ]
        self._execute_batch_update_with_retry(requests)
    
    def _update_worksheet_with_retry(self, worksheet, values, range_name, max_retries=3):
        """worksheet.updateã‚’ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§å®Ÿè¡Œï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰"""
        for attempt in range(max_retries):
            try:
                worksheet.update(values=values, range_name=range_name)
                time.sleep(0.2)  # æˆåŠŸå¾Œã‚‚å°‘ã—å¾…æ©Ÿ
                return True
            except Exception as e:
                if "429" in str(e) or "Quota exceeded" in str(e):
                    wait_time = (attempt + 1) * 3  # 3ç§’ã€6ç§’ã€9ç§’ã¨å¢—ã‚„ã™
                    print(f"      âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    logger.warning(f"Google Sheets APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    if attempt == max_retries - 1:
                        # ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ãŸå ´åˆã€ã•ã‚‰ã«é•·ãå¾…æ©Ÿã—ã¦æœ€å¾Œã®è©¦è¡Œ
                        print(f"      âš ï¸ ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«60ç§’å¾…æ©Ÿã—ã¦æœ€å¾Œã®è©¦è¡Œ...")
                        logger.warning("ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«60ç§’å¾…æ©Ÿã—ã¦æœ€å¾Œã®è©¦è¡Œ")
                        time.sleep(60)
                        try:
                            worksheet.update(values=values, range_name=range_name)
                            time.sleep(0.2)
                            print(f"      âœ… æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤æˆåŠŸ")
                            logger.info("æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤æˆåŠŸ")
                            return True
                        except Exception as final_error:
                            log_exception(logger, final_error, "æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤å¤±æ•—")
                            print(f"      âš ï¸ æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤ã‚‚å¤±æ•—ã€‚ã“ã®æ“ä½œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            return False
                else:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼ã¯è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦å†ç™ºç”Ÿ
                    log_exception(logger, e, "worksheet.updateã‚¨ãƒ©ãƒ¼")
                    raise
        return False
    
    def _execute_batch_update_with_retry(self, requests, max_retries=3):
        """ãƒãƒƒãƒæ›´æ–°ã‚’ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§å®Ÿè¡Œï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰"""
        for attempt in range(max_retries):
            try:
                self.spreadsheet.batch_update({'requests': requests})
                time.sleep(0.2)  # æˆåŠŸå¾Œã‚‚å°‘ã—å¾…æ©Ÿ
                return True
            except Exception as e:
                if "429" in str(e) or "Quota exceeded" in str(e):
                    wait_time = (attempt + 1) * 3  # 3ç§’ã€6ç§’ã€9ç§’ã¨å¢—ã‚„ã™
                    print(f"      âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    logger.warning(f"Google Sheets APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ï¼ˆãƒãƒƒãƒæ›´æ–°ï¼‰ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    if attempt == max_retries - 1:
                        # ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ãŸå ´åˆã€ã•ã‚‰ã«é•·ãå¾…æ©Ÿã—ã¦æœ€å¾Œã®è©¦è¡Œ
                        print(f"      âš ï¸ ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«60ç§’å¾…æ©Ÿã—ã¦æœ€å¾Œã®è©¦è¡Œ...")
                        logger.warning("ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ã¾ã—ãŸï¼ˆãƒãƒƒãƒæ›´æ–°ï¼‰ã€‚ã•ã‚‰ã«60ç§’å¾…æ©Ÿã—ã¦æœ€å¾Œã®è©¦è¡Œ")
                        time.sleep(60)
                        try:
                            self.spreadsheet.batch_update({'requests': requests})
                            time.sleep(0.2)
                            print(f"      âœ… æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤æˆåŠŸ")
                            logger.info("æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤æˆåŠŸï¼ˆãƒãƒƒãƒæ›´æ–°ï¼‰")
                            return True
                        except Exception as final_error:
                            log_exception(logger, final_error, "æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤å¤±æ•—ï¼ˆãƒãƒƒãƒæ›´æ–°ï¼‰")
                            print(f"      âš ï¸ æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤ã‚‚å¤±æ•—ã€‚ã“ã®æ“ä½œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            return False
                else:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼ã¯è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦å†ç™ºç”Ÿ
                    log_exception(logger, e, "batch_updateã‚¨ãƒ©ãƒ¼")
                    raise
        return False
    
    def _load_existing_urls(self):
        """å…¨ã‚·ãƒ¼ãƒˆã‹ã‚‰æ—¢å­˜URLã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        total = 0
        self.existing_titles = set()
        for category, ws in self.worksheets.items():
            try:
                all_values = ws.get_all_values()
                for row in all_values[1:]:
                    if len(row) >= 3:
                        # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆCåˆ—ï¼‰ã‚’ä¿å­˜
                        self.existing_titles.add(row[2])
                        total += 1
            except Exception as e:
                log_exception(logger, e, f"ã‚·ãƒ¼ãƒˆã€Œ{category}ã€ã‹ã‚‰æ—¢å­˜URLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
        if total > 0:
            print(f"   æ—¢å­˜è¨˜äº‹æ•°: {total}ä»¶")
            logger.info(f"æ—¢å­˜è¨˜äº‹æ•°: {total}ä»¶")
    
    def is_duplicate(self, url: str, title: str = "") -> bool:
        """URLã¾ãŸã¯ã‚¿ã‚¤ãƒˆãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if url in self.existing_urls:
            return True
        if title and title in self.existing_titles:
            return True
        return False
    
    def _get_category(self, article: dict) -> str:
        """è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®šï¼ˆè¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œï¼‰"""
        text = f"{article.get('title', '')} {' '.join(article.get('tags', []))} {article.get('content', '')[:500]}"
        text_lower = text.lower()
        
        # ãƒãƒƒãƒã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’å…¨ã¦åé›†
        matched_categories = []
        
        # å„ªå…ˆé †ä½é †ã«ãƒã‚§ãƒƒã‚¯ï¼ˆä¼æ¥­åŠ¹ç‡åŒ–ã€DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã‚’å„ªå…ˆï¼‰
        category_priority = [
            "ä¼æ¥­åŠ¹ç‡åŒ–",
            "DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–",
            "ä¼æ¥­å°å…¥",
            "AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼",
        ]
        
        for category in category_priority:
            if category in KEYWORD_CATEGORIES:
                keywords = KEYWORD_CATEGORIES[category]
                if any(kw.lower() in text_lower for kw in keywords):
                    matched_categories.append(category)
        
        # ãƒãƒƒãƒã—ãŸã‚«ãƒ†ã‚´ãƒªãŒãªã„å ´åˆã¯ã€Œãã®ä»–ã€
        if not matched_categories:
            return "ãã®ä»–"
        
        # è¤‡æ•°ãƒãƒƒãƒã—ãŸå ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿”ã™
        # ãŸã ã—ã€ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªï¼ˆæœ€åˆã«ãƒãƒƒãƒã—ãŸã‚‚ã®ï¼‰ã‚’æœ€åˆã«é…ç½®
        return ", ".join(matched_categories)
    
    def add_article(self, article: dict, summary: str, score: int = 3) -> bool:
        """è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚·ãƒ¼ãƒˆã«è¿½åŠ ï¼ˆè¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œï¼‰"""
        url = article.get("url", "")
        title = article.get("title", "")
        
        if self.is_duplicate(url, title):
            return False
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šï¼ˆè¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
        category_str = self._get_category(article)
        categories = [cat.strip() for cat in category_str.split(",")]
        
        # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªï¼ˆæœ€åˆã®ã‚«ãƒ†ã‚´ãƒªï¼‰ã®ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
        main_category = categories[0] if categories else "ãã®ä»–"
        
        # ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        if main_category not in self.worksheets:
            try:
                ws = self.spreadsheet.worksheet(main_category)
                self.worksheets[main_category] = ws
            except gspread.WorksheetNotFound:
                # æ–°ã—ã„ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
                ws = self.spreadsheet.add_worksheet(title=main_category, rows=200, cols=10)
                self.worksheets[main_category] = ws
                self._setup_sheet_headers(ws, main_category)
                print(f"   ğŸ“„ æ–°è¦ã‚·ãƒ¼ãƒˆã€Œ{main_category}ã€ã‚’ä½œæˆã—ã¾ã—ãŸ")
        
        worksheet = self.worksheets.get(main_category, self.worksheets.get("ãã®ä»–"))
        
        row_num = len(worksheet.col_values(1)) + 1
        article_no = row_num - 1
        
        # é‡è¦åº¦ã‚’æ˜Ÿã§è¡¨ç¤º
        score_display = "â­" * score + "â˜†" * (5 - score)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ï¼ˆIåˆ—ã«å®ŸURLã‚’ä¿å­˜ï¼‰
        # ã‚«ãƒ†ã‚´ãƒªåˆ—ã«ã¯è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§ä¿å­˜
        data = [
            article_no,
            article.get("source", ""),
            article.get("title", ""),
            article.get("date", ""),
            ", ".join(article.get("tags", [])),
            score_display,  # é‡è¦åº¦
            summary,
            "",  # URLåˆ—ã¯å¾Œã§ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯è¨­å®š
            url,   # å®ŸURLï¼ˆWebã‚¢ãƒ—ãƒªç”¨ï¼‰
            category_str  # ã‚«ãƒ†ã‚´ãƒªï¼ˆè¤‡æ•°ã®å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
        ]
        
        # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
        self._update_worksheet_with_retry(worksheet, values=[data], range_name=f'A{row_num}:J{row_num}')
        self.existing_urls.add(url)
        self.existing_titles.add(title)
        
        # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸèƒŒæ™¯è‰²
        score_colors = {
            5: {'red': 1.0, 'green': 0.9, 'blue': 0.6},    # é‡‘è‰²
            4: {'red': 0.9, 'green': 0.95, 'blue': 0.7},   # è–„ç·‘
            3: {'red': 1.0, 'green': 1.0, 'blue': 1.0},    # ç™½
            2: {'red': 0.95, 'green': 0.95, 'blue': 0.95}, # è–„ç°
            1: {'red': 0.9, 'green': 0.9, 'blue': 0.9},    # ç°è‰²
        }
        score_bg = score_colors.get(score, score_colors[3])
        
        # è¡Œã®æ›¸å¼è¨­å®š + URLã‚’ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ã¨ã—ã¦è¨­å®š
        sheet_id = worksheet.id
        requests = [
                # è¡Œã®æ›¸å¼è¨­å®š
                {'repeatCell': {
                    'range': {'sheetId': sheet_id, 'startRowIndex': row_num - 1, 'endRowIndex': row_num, 'startColumnIndex': 0, 'endColumnIndex': 7},
                    'cell': {'userEnteredFormat': {'wrapStrategy': 'WRAP', 'verticalAlignment': 'TOP', 'textFormat': {'fontSize': 10}}},
                    'fields': 'userEnteredFormat(wrapStrategy,verticalAlignment,textFormat)'
                }},
                # é‡è¦åº¦ã‚»ãƒ«ã®æ›¸å¼ï¼ˆä¸­å¤®æƒãˆ + èƒŒæ™¯è‰²ï¼‰
                {'repeatCell': {
                    'range': {'sheetId': sheet_id, 'startRowIndex': row_num - 1, 'endRowIndex': row_num, 'startColumnIndex': 5, 'endColumnIndex': 6},
                    'cell': {'userEnteredFormat': {
                        'horizontalAlignment': 'CENTER',
                        'verticalAlignment': 'MIDDLE',
                        'backgroundColor': score_bg
                    }},
                    'fields': 'userEnteredFormat(horizontalAlignment,verticalAlignment,backgroundColor)'
                }},
                # è¡Œã®é«˜ã•
                {'updateDimensionProperties': {
                    'range': {'sheetId': sheet_id, 'dimension': 'ROWS', 'startIndex': row_num - 1, 'endIndex': row_num},
                    'properties': {'pixelSize': 120}, 'fields': 'pixelSize'}},
                # URLã‚’ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ã¨ã—ã¦è¨­å®š
                {'updateCells': {
                    'range': {'sheetId': sheet_id, 'startRowIndex': row_num - 1, 'endRowIndex': row_num, 'startColumnIndex': 7, 'endColumnIndex': 8},
                    'rows': [{
                        'values': [{
                            'userEnteredValue': {'stringValue': 'ğŸ”— è¨˜äº‹ã‚’é–‹ã'},
                            'textFormatRuns': [{
                                'startIndex': 0,
                                'format': {'link': {'uri': url}, 'foregroundColor': {'red': 0.06, 'green': 0.46, 'blue': 0.88}}
                            }]
                        }]
                    }],
                    'fields': 'userEnteredValue,textFormatRuns'
                }}
            ]
        self._execute_batch_update_with_retry(requests)
        
        return True
    
    def get_spreadsheet_url(self) -> str:
        """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URLã‚’å–å¾—"""
        return self.spreadsheet.url
    
    def get_total_article_count(self) -> int:
        """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ç·è¨˜äº‹æ•°ã‚’å–å¾—"""
        total = 0
        for category, ws in self.worksheets.items():
            try:
                all_values = ws.get_all_values()
                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã„ãŸæœ‰åŠ¹ãªè¨˜äº‹æ•°ï¼ˆ7åˆ—ä»¥ä¸Šã‚ã‚‹è¡Œï¼‰
                for row in all_values[1:]:
                    if len(row) >= 7 and row[2]:  # ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚‹è¡Œ
                        total += 1
            except Exception as e:
                log_exception(logger, e, f"ã‚·ãƒ¼ãƒˆã€Œ{category}ã€ã®è¨˜äº‹æ•°å–å¾—ã‚¨ãƒ©ãƒ¼")
        return total


def filter_by_keywords(articles: list[dict]) -> list[dict]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç·©å’Œç‰ˆï¼šã‚ˆã‚Šå¤šãã®è¨˜äº‹ã‚’é€šã™ï¼‰"""
    filtered = []
    for article in articles:
        # ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¿ã‚°ã€æœ¬æ–‡ã®æœ€åˆã®1000æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç¯„å›²ã‚’æ‹¡å¤§ï¼‰
        text = f"{article.get('title', '')} {' '.join(article.get('tags', []))} {article.get('content', '')[:1000]}"
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼ˆéƒ¨åˆ†ä¸€è‡´ã§ã‚‚OKï¼‰
        if any(keyword.lower() in text.lower() for keyword in KEYWORDS):
            filtered.append(article)
    return filtered


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 70)
    print("ğŸ¤– ãƒãƒ«ãƒã‚µã‚¤ãƒˆå¯¾å¿œ AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & è¦ç´„ãƒ„ãƒ¼ãƒ«")
    print("   ğŸ“° å¯¾å¿œã‚µã‚¤ãƒˆ: Ledge.ai, AINOW, PR TIMES, ZDNet Japan, ITmedia AI+")
    print("=" * 70)
    
    logger.info("=" * 70)
    logger.info("ãƒãƒ«ãƒã‚µã‚¤ãƒˆå¯¾å¿œ AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & è¦ç´„ãƒ„ãƒ¼ãƒ«ã‚’é–‹å§‹")
    logger.info("å¯¾å¿œã‚µã‚¤ãƒˆ: Ledge.ai, AINOW, PR TIMES, ZDNet Japan, ITmedia AI+")
    logger.info("=" * 70)
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        error_msg = "OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        logger.error(error_msg)
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_msg}")
        return
    
    print(f"âœ… OpenAI APIã‚­ãƒ¼: è¨­å®šæ¸ˆã¿")
    logger.info("OpenAI APIã‚­ãƒ¼: è¨­å®šæ¸ˆã¿")
    
    # Google SheetsåˆæœŸåŒ–
    try:
        exporter = GoogleSheetsExporter()
    except Exception as e:
        log_exception(logger, e, "Google SheetsåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼")
        print(f"âŒ Google Sheetsèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒªã‚¹ãƒˆ
    scrapers = [
        LedgeAiScraper(),
        AINowScraper(),
        PRTimesScraper(),
        ZDNetScraper(),
        ITmediaAiPlusScraper(),
    ]
    
    # å…¨ã‚µã‚¤ãƒˆã‹ã‚‰è¨˜äº‹ã‚’åé›†
    all_articles = []
    for scraper in scrapers:
        try:
            # ã‚ˆã‚Šå¤šãã®è¨˜äº‹ã‚’å–å¾—ï¼ˆmax_pagesã¨max_articlesã‚’å¢—ã‚„ã™ï¼‰
            articles = scraper.scrape(max_pages=10, max_articles=30)
            print(f"   ğŸ“° {scraper.SITE_NAME}: {len(articles)}ä»¶å–å¾—")
            logger.info(f"{scraper.SITE_NAME}: {len(articles)}ä»¶å–å¾—")
            all_articles.extend(articles)
        except Exception as e:
            log_exception(logger, e, f"{scraper.SITE_NAME} ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼")
            print(f"âš ï¸ {scraper.SITE_NAME} ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nğŸ“Š å…¨ã‚µã‚¤ãƒˆåˆè¨ˆ: {len(all_articles)}ä»¶")
    
    # ã‚µã‚¤ãƒˆåˆ¥å†…è¨³ã‚’è¡¨ç¤º
    source_counts = {}
    for article in all_articles:
        source = article.get("source", "Unknown")
        source_counts[source] = source_counts.get(source, 0) + 1
    print("   ğŸ“‚ ã‚µã‚¤ãƒˆåˆ¥å†…è¨³:")
    for source, count in source_counts.items():
        print(f"      - {source}: {count}ä»¶")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    print("\nğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")
    filtered_articles = filter_by_keywords(all_articles)
    print(f"   ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(filtered_articles)}ä»¶")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ã‚µã‚¤ãƒˆåˆ¥å†…è¨³
    filtered_source_counts = {}
    for article in filtered_articles:
        source = article.get("source", "Unknown")
        filtered_source_counts[source] = filtered_source_counts.get(source, 0) + 1
    print("   ğŸ“‚ ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ã‚µã‚¤ãƒˆåˆ¥å†…è¨³:")
    for source, count in filtered_source_counts.items():
        print(f"      - {source}: {count}ä»¶")
    
    # é‡è¤‡é™¤å¤–
    new_articles = [a for a in filtered_articles if not exporter.is_duplicate(a.get("url", ""), a.get("title", ""))]
    skipped = len(filtered_articles) - len(new_articles)
    
    if skipped > 0:
        print(f"   â­ï¸ æ—¢å­˜è¨˜äº‹ã‚’ã‚¹ã‚­ãƒƒãƒ—: {skipped}ä»¶")
    
    if not new_articles:
        print("\nâœ… æ–°ã—ã„è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        print(f"ğŸ”— ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ: {exporter.get_spreadsheet_url()}")
        return
    
    print(f"   ğŸ†• æ–°è¦è¨˜äº‹: {len(new_articles)}ä»¶")
    
    # è¦ç´„ç”Ÿæˆ + é‡è¦åº¦ã‚¹ã‚³ã‚¢
    summarizer = ArticleSummarizer(api_key)
    print("\nâœï¸ OpenAI APIã§è¦ç´„ & é‡è¦åº¦è©•ä¾¡ä¸­...")
    
    added = 0
    score_stats = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}
    
    for i, article in enumerate(new_articles, 1):
        source = article.get('source', '')
        title = article.get('title', '')[:35]
        print(f"   [{i}/{len(new_articles)}] [{source}] {title}...")
        logger.info(f"[{i}/{len(new_articles)}] [{source}] {title[:50]}...")
        
        try:
            result = summarizer.summarize_and_score(article)
            summary = result["summary"]
            score = result["score"]
            score_stats[score] += 1
            
            print(f"      â†’ é‡è¦åº¦: {'â­' * score}")
            logger.info(f"é‡è¦åº¦: {'â­' * score}")
            
            if exporter.add_article(article, summary, score):
                added += 1
                logger.info(f"è¨˜äº‹ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {title[:50]}")
            else:
                logger.warning(f"è¨˜äº‹ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆé‡è¤‡ã®å¯èƒ½æ€§ï¼‰: {title[:50]}")
        except Exception as e:
            log_exception(logger, e, f"è¨˜äº‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {title[:50]}")
            print(f"      âš ï¸ è¨˜äº‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        time.sleep(0.5)
    
    # ã‚µã‚¤ãƒˆåˆ¥é›†è¨ˆ
    source_counts = {}
    for article in new_articles:
        source = article.get('source', 'Unknown')
        source_counts[source] = source_counts.get(source, 0) + 1
    
    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ç·è¨˜äº‹æ•°ã‚’å–å¾—
    total_articles = exporter.get_total_article_count()
    
    print("\n" + "=" * 70)
    print("ğŸ‰ å‡¦ç†å®Œäº†ï¼")
    print(f"   ğŸ“Š åé›†è¨˜äº‹æ•°: {len(filtered_articles)}ä»¶")
    print(f"   â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {skipped}ä»¶")
    print(f"   ğŸ†• æ–°è¦è¿½åŠ : {added}ä»¶")
    print(f"   ğŸ“‚ ã‚µã‚¤ãƒˆåˆ¥å†…è¨³:")
    for source, count in source_counts.items():
        print(f"      - {source}: {count}ä»¶")
    print(f"   â­ é‡è¦åº¦åˆ†å¸ƒ:")
    print(f"      - â­â­â­â­â­ (å¿…èª­): {score_stats[5]}ä»¶")
    print(f"      - â­â­â­â­â˜† (é‡è¦): {score_stats[4]}ä»¶")
    print(f"      - â­â­â­â˜†â˜† (å‚è€ƒ): {score_stats[3]}ä»¶")
    print(f"      - â­â­â˜†â˜†â˜† (è»½ã„): {score_stats[2]}ä»¶")
    print(f"      - â­â˜†â˜†â˜†â˜† (ä½ã„): {score_stats[1]}ä»¶")
    print(f"   ğŸ“ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç·è¨˜äº‹æ•°: {total_articles}ä»¶")
    print(f"   ğŸ”— ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ: {exporter.get_spreadsheet_url()}")
    print("=" * 70)
    
    logger.info("=" * 70)
    logger.info("å‡¦ç†å®Œäº†")
    logger.info(f"åé›†è¨˜äº‹æ•°: {len(filtered_articles)}ä»¶")
    logger.info(f"ã‚¹ã‚­ãƒƒãƒ—: {skipped}ä»¶")
    logger.info(f"æ–°è¦è¿½åŠ : {added}ä»¶")
    logger.info(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç·è¨˜äº‹æ•°: {total_articles}ä»¶")
    logger.info("=" * 70)


if __name__ == "__main__":
    main()

