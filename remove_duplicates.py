#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡è¤‡è¨˜äº‹å‰Šé™¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Google Sheetsã‹ã‚‰é‡è¤‡ã—ãŸè¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã™
- URLãŒåŒã˜è¨˜äº‹
- ã‚¿ã‚¤ãƒˆãƒ«ãŒåŒã˜è¨˜äº‹
"""

import os
import re
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import gspread

# Google Sheets APIã®ã‚¹ã‚³ãƒ¼ãƒ—
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive.file'
]

# èªè¨¼æƒ…å ±ã®ãƒ‘ã‚¹
CREDENTIALS_FILE = "/Users/masak/Desktop/ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°/credentials.json"
TOKEN_FILE = "/Users/masak/Desktop/ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°/token.json"

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå
SPREADSHEET_NAME = "Ledge.ai AIãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„"

# åˆ†é¡ã”ã¨ã®ã‚·ãƒ¼ãƒˆå
SHEET_NAMES = ["ä¼æ¥­åŠ¹ç‡åŒ–", "DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–", "ä¼æ¥­å°å…¥", "ãã®ä»–"]


def normalize_url(url: str) -> str:
    """URLã‚’æ­£è¦åŒ–ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰"""
    if not url:
        return ""
    
    # HYPERLINKé–¢æ•°ã‹ã‚‰å®Ÿéš›ã®URLã‚’æŠ½å‡º
    if url.startswith('=HYPERLINK') or url.startswith('=hyperlink') or 'HYPERLINK' in url.upper():
        match = re.search(r'HYPERLINK\("([^"]+)"', url, re.IGNORECASE)
        if match:
            url = match.group(1)
    
    # URLã‚’æ­£è¦åŒ–
    url = url.strip()
    
    # "è¨˜äº‹ã‚’é–‹ã"ãªã©ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é™¤å¤–
    if url == "è¨˜äº‹ã‚’é–‹ã" or url == "Open Article":
        return ""
    
    # æœ«å°¾ã®ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
    url = url.rstrip('/')
    
    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å‰Šé™¤ï¼ˆè¨˜äº‹URLã¯é€šå¸¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦ï¼‰
    if '?' in url:
        base, params = url.split('?', 1)
        # é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: id, article_idï¼‰ãŒã‚ã‚‹å ´åˆã¯ä¿æŒ
        if 'id=' in params.lower() or 'article_id=' in params.lower():
            # IDãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ä¿æŒ
            param_dict = {}
            for param in params.split('&'):
                if '=' in param:
                    key, value = param.split('=', 1)
                    if key.lower() in ['id', 'article_id', 'article']:
                        param_dict[key] = value
            if param_dict:
                sorted_params = '&'.join([f"{k}={v}" for k, v in sorted(param_dict.items())])
                url = f"{base}?{sorted_params}"
            else:
                url = base
        else:
            url = base
    
    return url


def normalize_title(title: str) -> str:
    """ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰"""
    if not title:
        return ""
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ï¼ˆç©ºç™½ã‚’çµ±ä¸€ã€å¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ã€ç‰¹æ®Šæ–‡å­—ã‚’é™¤å»ï¼‰
    normalized = title.lower().replace(" ", "").replace("ã€€", "").replace("ã€", "").replace("ï¼Œ", "")
    normalized = normalized.replace("ãƒ»", "").replace("ãƒ¼", "").replace("-", "").replace("â€•", "")
    return normalized


def authenticate():
    """Googleèªè¨¼ã‚’è¡Œã†"""
    print("ğŸ” Googleèªè¨¼ä¸­...")
    
    creds = None
    
    # æ—¢å­˜ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
    if os.path.exists(TOKEN_FILE):
        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)
    
    # èªè¨¼ãŒå¿…è¦ãªå ´åˆ
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
            creds = flow.run_local_server(port=0)
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
    
    client = gspread.authorize(creds)
    print("âœ… Googleèªè¨¼å®Œäº†")
    return client


def remove_duplicates():
    """é‡è¤‡è¨˜äº‹ã‚’å‰Šé™¤"""
    print("=" * 60)
    print("ğŸ—‘ï¸  é‡è¤‡è¨˜äº‹å‰Šé™¤ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    # èªè¨¼
    client = authenticate()
    
    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã
    try:
        spreadsheet = client.open(SPREADSHEET_NAME)
        print(f"ğŸ“‚ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ãã¾ã—ãŸ: {SPREADSHEET_NAME}")
    except gspread.SpreadsheetNotFound:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã€Œ{SPREADSHEET_NAME}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    total_deleted = 0
    
    # å„ã‚·ãƒ¼ãƒˆã‚’å‡¦ç†
    for sheet_name in SHEET_NAMES:
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
            print(f"\nğŸ“‹ ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’å‡¦ç†ä¸­...")
        except gspread.WorksheetNotFound:
            print(f"   âš ï¸ ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        all_values = worksheet.get_all_values()
        if len(all_values) <= 1:
            print(f"   ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã
        data_rows = all_values[1:]
        
        # é‡è¤‡ã‚’æ¤œå‡º
        seen_urls = {}
        seen_titles = {}
        rows_to_delete = []
        
        for row_index, row in enumerate(data_rows, start=2):  # 2è¡Œç›®ã‹ã‚‰ï¼ˆ1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰
            if len(row) < 7:
                continue
            
            title = row[1] if len(row) > 1 else ""
            url = row[6] if len(row) > 6 else ""
            
            # URLã‚’æ­£è¦åŒ–
            normalized_url = normalize_url(url)
            normalized_title = normalize_title(title)
            
            # URLãƒ™ãƒ¼ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if normalized_url and normalized_url in seen_urls:
                rows_to_delete.append(row_index)
                print(f"   ğŸ—‘ï¸  è¡Œ{row_index}: URLé‡è¤‡ - {title[:50]}...")
                total_deleted += 1
                continue
            
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if normalized_title and normalized_title in seen_titles:
                rows_to_delete.append(row_index)
                print(f"   ğŸ—‘ï¸  è¡Œ{row_index}: ã‚¿ã‚¤ãƒˆãƒ«é‡è¤‡ - {title[:50]}...")
                total_deleted += 1
                continue
            
            # è¨˜éŒ²
            if normalized_url:
                seen_urls[normalized_url] = row_index
            if normalized_title:
                seen_titles[normalized_title] = row_index
        
        # é‡è¤‡è¡Œã‚’å‰Šé™¤ï¼ˆå¾Œã‚ã‹ã‚‰å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
        if rows_to_delete:
            # é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå¾Œã‚ã®è¡Œã‹ã‚‰å‰Šé™¤ï¼‰
            rows_to_delete.sort(reverse=True)
            
            for row_index in rows_to_delete:
                try:
                    worksheet.delete_rows(row_index)
                    print(f"      âœ… è¡Œ{row_index}ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                except Exception as e:
                    print(f"      âš ï¸ è¡Œ{row_index}ã®å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print(f"   âœ… é‡è¤‡ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å‡¦ç†å®Œäº†ï¼")
    print(f"   ğŸ—‘ï¸  å‰Šé™¤ã—ãŸè¨˜äº‹æ•°: {total_deleted}ä»¶")
    print("=" * 60)


if __name__ == "__main__":
    try:
        remove_duplicates()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

